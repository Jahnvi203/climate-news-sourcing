{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbd1332",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bef9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jingy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gensim\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from textblob import TextBlob\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3301f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_basic = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4df1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_climate = spacy.load(r\"NER model/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3165adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_opinion_classifier = pipeline(model=\"lighteternal/fact-or-opinion-xlmr-el\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f5c11",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "As the analysis requires alot of time, I created a df with only 10 news article for sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d0e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv('all_articles_cleaned_no_unnecessary_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40e4ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, San Francisco This video can not be played G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Atlantic hurricanes are retaining far mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US President Donald Trump has accused climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video can not be played Sir Ed Davey has won t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenland is not used to being the centre of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microsoft is poised to launch its game streami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video can not be played A frequent flyer tax, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>People must use less transport, eat less red m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>verely hindered progress in CO2 emissions redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>European Union says it is aiming to become the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  , San Francisco This video can not be played G...\n",
       "1  North Atlantic hurricanes are retaining far mo...\n",
       "2  US President Donald Trump has accused climate ...\n",
       "3  video can not be played Sir Ed Davey has won t...\n",
       "4  Greenland is not used to being the centre of a...\n",
       "5  Microsoft is poised to launch its game streami...\n",
       "6  video can not be played A frequent flyer tax, ...\n",
       "7  People must use less transport, eat less red m...\n",
       "8  verely hindered progress in CO2 emissions redu...\n",
       "9  European Union says it is aiming to become the..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_sample_df = articles_df.head(10)[['body']]\n",
    "\n",
    "articles_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a299a9",
   "metadata": {},
   "source": [
    "## Step 1: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157d36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_preprocess(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text).split()\n",
    "    meaningful_words = [w for w in text if w not in STOPS]\n",
    "    return (\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fea6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(df): \n",
    "    nerdict = {'PERSON': {}, 'ORG': {}, 'EVENT': {}, 'GPE': {}, 'LOC': {}}\n",
    "    \n",
    "    # normal entities\n",
    "    doc = ner_basic(df['body'])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in nerdict.keys():\n",
    "            if ent.text in nerdict[ent.label_].keys():\n",
    "                nerdict[ent.label_][ent.text] += 1\n",
    "            else:\n",
    "                nerdict[ent.label_][ent.text] = 1\n",
    "           \n",
    "    # climate entities\n",
    "    climatedoc = ner_climate(df['body'])\n",
    "    climatedict = {}\n",
    "    for ent in climatedoc.ents:\n",
    "        if ent.text in climatedict.keys() and ent.label_ == \"CLIMATE\":\n",
    "            climatedict[ent.text] += 1\n",
    "        else:\n",
    "            climatedict[ent.text] = 1\n",
    "    nerdict[\"CLIMATE\"] = climatedict\n",
    "        \n",
    "    # sorting of entities\n",
    "    for key in nerdict.keys():\n",
    "        ndict = nerdict[key]\n",
    "        keys = list(ndict.keys())\n",
    "        values = list(ndict.values())\n",
    "        sorted_value_index = np.argsort(values)[::-1]\n",
    "        ndict = {keys[i]: values[i] for i in sorted_value_index}\n",
    "        nerdict[key] = ndict\n",
    "    \n",
    "    for ner in nerdict:\n",
    "        df[ner] = nerdict[ner]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a62758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_sample_df[\"clean body\"] = articles_sample_df[\"body\"].apply(ner_preprocess)\n",
    "\n",
    "articles_sample_df = articles_sample_df.apply(ner, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da5e4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LOC</th>\n",
       "      <th>CLIMATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, San Francisco This video can not be played G...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 9, 'Ukraine': 2, 'San Francisco'...</td>\n",
       "      <td>{'Earth': 2, 'Central Europe': 1, 'south': 1, ...</td>\n",
       "      <td>{'sea-level rise': 3, 'ocean': 2, 'flooding': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Atlantic hurricanes are retaining far mo...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{'Hurricane Theta': 1}</td>\n",
       "      <td>{'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'North Atlantic': 2, 'Central Europe': 1, 'th...</td>\n",
       "      <td>{'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US President Donald Trump has accused climate ...</td>\n",
       "      <td>{'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...</td>\n",
       "      <td>{'Central Europe': 1, 'earth': 1}</td>\n",
       "      <td>{'climate change': 3, 'IPCC': 2, 'Climate chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video can not be played Sir Ed Davey has won t...</td>\n",
       "      <td>{'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...</td>\n",
       "      <td>{'BBC': 2, 'Parliament': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenland is not used to being the centre of a...</td>\n",
       "      <td>{'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...</td>\n",
       "      <td>{'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 22, 'US': 14, 'China': 4, 'Denma...</td>\n",
       "      <td>{'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microsoft is poised to launch its game streami...</td>\n",
       "      <td>{'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...</td>\n",
       "      <td>{'Microsoft': 3, 'Google': 2, 'Lancaster Unive...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video can not be played A frequent flyer tax, ...</td>\n",
       "      <td>{'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>People must use less transport, eat less red m...</td>\n",
       "      <td>{'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...</td>\n",
       "      <td>{'BBC': 1, 'the Confederation of British Indus...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'Net Zero': 2, 'rise': 1, 'good position': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>verely hindered progress in CO2 emissions redu...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'greenhouse gases': 3, 'CO2 emissions': 2, 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>European Union says it is aiming to become the...</td>\n",
       "      <td>{'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...</td>\n",
       "      <td>{'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...</td>\n",
       "      <td>{'Europe': 2, 'Central Europe': 1}</td>\n",
       "      <td>{'net-zero emissions': 3, 'emissions': 2, 'ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  , San Francisco This video can not be played G...   \n",
       "1  North Atlantic hurricanes are retaining far mo...   \n",
       "2  US President Donald Trump has accused climate ...   \n",
       "3  video can not be played Sir Ed Davey has won t...   \n",
       "4  Greenland is not used to being the centre of a...   \n",
       "5  Microsoft is poised to launch its game streami...   \n",
       "6  video can not be played A frequent flyer tax, ...   \n",
       "7  People must use less transport, eat less red m...   \n",
       "8  verely hindered progress in CO2 emissions redu...   \n",
       "9  European Union says it is aiming to become the...   \n",
       "\n",
       "                                              PERSON  \\\n",
       "0  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "1  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "2  {'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...   \n",
       "3  {'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...   \n",
       "4  {'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...   \n",
       "5  {'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...   \n",
       "6  {'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...   \n",
       "7  {'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...   \n",
       "8  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "9  {'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...   \n",
       "\n",
       "                                                 ORG                   EVENT  \\\n",
       "0  {'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...                      {}   \n",
       "1  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...  {'Hurricane Theta': 1}   \n",
       "2  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "3  {'BBC': 2, 'Parliament': 2, 'Micah Richards': ...                      {}   \n",
       "4  {'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...                      {}   \n",
       "5  {'Microsoft': 3, 'Google': 2, 'Lancaster Unive...                      {}   \n",
       "6  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "7  {'BBC': 1, 'the Confederation of British Indus...                      {}   \n",
       "8  {'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...                      {}   \n",
       "9  {'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...                      {}   \n",
       "\n",
       "                                                 GPE  \\\n",
       "0  {'Greenland': 9, 'Ukraine': 2, 'San Francisco'...   \n",
       "1  {'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...   \n",
       "2  {'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...   \n",
       "3  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "4  {'Greenland': 22, 'US': 14, 'China': 4, 'Denma...   \n",
       "5  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "6  {'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "7  {'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "8  {'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...   \n",
       "9  {'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...   \n",
       "\n",
       "                                                 LOC  \\\n",
       "0  {'Earth': 2, 'Central Europe': 1, 'south': 1, ...   \n",
       "1  {'North Atlantic': 2, 'Central Europe': 1, 'th...   \n",
       "2                  {'Central Europe': 1, 'earth': 1}   \n",
       "3                              {'Central Europe': 1}   \n",
       "4  {'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...   \n",
       "5                              {'Central Europe': 1}   \n",
       "6                              {'Central Europe': 1}   \n",
       "7                              {'Central Europe': 1}   \n",
       "8                              {'Central Europe': 1}   \n",
       "9                 {'Europe': 2, 'Central Europe': 1}   \n",
       "\n",
       "                                             CLIMATE  \n",
       "0  {'sea-level rise': 3, 'ocean': 2, 'flooding': ...  \n",
       "1  {'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...  \n",
       "2  {'climate change': 3, 'IPCC': 2, 'Climate chan...  \n",
       "3  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "4  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "5  {'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...  \n",
       "6  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "7  {'Net Zero': 2, 'rise': 1, 'good position': 1,...  \n",
       "8  {'greenhouse gases': 3, 'CO2 emissions': 2, 'o...  \n",
       "9  {'net-zero emissions': 3, 'emissions': 2, 'ris...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6475c3",
   "metadata": {},
   "source": [
    "## Step 2: Additional Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd83ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess_keepstopwords(self_text):\n",
    "    # 1. Remove html tags\n",
    "    words = BeautifulSoup(self_text, features=\"html.parser\").get_text()\n",
    "    \n",
    "    # 2. Convert words to lower case and split each word up\n",
    "    words = self_text.lower()\n",
    "    words = words.replace('\\n','')\n",
    "    \n",
    "    # remove punctuation \n",
    "    punc = '''()-[]{};:\\,<>/@#$%^&*_~'''\n",
    "    for ele in punc:\n",
    "        words = words.replace(ele, \"\")\n",
    "     \n",
    "    words = words.encode('ascii', 'ignore')\n",
    "    words = words.decode()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1702c1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LOC</th>\n",
       "      <th>CLIMATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>san francisco this video can not be played gr...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 9, 'Ukraine': 2, 'San Francisco'...</td>\n",
       "      <td>{'Earth': 2, 'Central Europe': 1, 'south': 1, ...</td>\n",
       "      <td>{'sea-level rise': 3, 'ocean': 2, 'flooding': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north atlantic hurricanes are retaining far mo...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{'Hurricane Theta': 1}</td>\n",
       "      <td>{'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'North Atlantic': 2, 'Central Europe': 1, 'th...</td>\n",
       "      <td>{'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us president donald trump has accused climate ...</td>\n",
       "      <td>{'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...</td>\n",
       "      <td>{'Central Europe': 1, 'earth': 1}</td>\n",
       "      <td>{'climate change': 3, 'IPCC': 2, 'Climate chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video can not be played sir ed davey has won t...</td>\n",
       "      <td>{'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...</td>\n",
       "      <td>{'BBC': 2, 'Parliament': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greenland is not used to being the centre of a...</td>\n",
       "      <td>{'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...</td>\n",
       "      <td>{'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 22, 'US': 14, 'China': 4, 'Denma...</td>\n",
       "      <td>{'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft is poised to launch its game streami...</td>\n",
       "      <td>{'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...</td>\n",
       "      <td>{'Microsoft': 3, 'Google': 2, 'Lancaster Unive...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video can not be played a frequent flyer tax p...</td>\n",
       "      <td>{'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>people must use less transport eat less red me...</td>\n",
       "      <td>{'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...</td>\n",
       "      <td>{'BBC': 1, 'the Confederation of British Indus...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'Net Zero': 2, 'rise': 1, 'good position': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>verely hindered progress in co2 emissions redu...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'greenhouse gases': 3, 'CO2 emissions': 2, 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>european union says it is aiming to become the...</td>\n",
       "      <td>{'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...</td>\n",
       "      <td>{'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...</td>\n",
       "      <td>{'Europe': 2, 'Central Europe': 1}</td>\n",
       "      <td>{'net-zero emissions': 3, 'emissions': 2, 'ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0   san francisco this video can not be played gr...   \n",
       "1  north atlantic hurricanes are retaining far mo...   \n",
       "2  us president donald trump has accused climate ...   \n",
       "3  video can not be played sir ed davey has won t...   \n",
       "4  greenland is not used to being the centre of a...   \n",
       "5  microsoft is poised to launch its game streami...   \n",
       "6  video can not be played a frequent flyer tax p...   \n",
       "7  people must use less transport eat less red me...   \n",
       "8  verely hindered progress in co2 emissions redu...   \n",
       "9  european union says it is aiming to become the...   \n",
       "\n",
       "                                              PERSON  \\\n",
       "0  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "1  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "2  {'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...   \n",
       "3  {'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...   \n",
       "4  {'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...   \n",
       "5  {'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...   \n",
       "6  {'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...   \n",
       "7  {'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...   \n",
       "8  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "9  {'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...   \n",
       "\n",
       "                                                 ORG                   EVENT  \\\n",
       "0  {'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...                      {}   \n",
       "1  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...  {'Hurricane Theta': 1}   \n",
       "2  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "3  {'BBC': 2, 'Parliament': 2, 'Micah Richards': ...                      {}   \n",
       "4  {'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...                      {}   \n",
       "5  {'Microsoft': 3, 'Google': 2, 'Lancaster Unive...                      {}   \n",
       "6  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "7  {'BBC': 1, 'the Confederation of British Indus...                      {}   \n",
       "8  {'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...                      {}   \n",
       "9  {'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...                      {}   \n",
       "\n",
       "                                                 GPE  \\\n",
       "0  {'Greenland': 9, 'Ukraine': 2, 'San Francisco'...   \n",
       "1  {'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...   \n",
       "2  {'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...   \n",
       "3  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "4  {'Greenland': 22, 'US': 14, 'China': 4, 'Denma...   \n",
       "5  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "6  {'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "7  {'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "8  {'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...   \n",
       "9  {'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...   \n",
       "\n",
       "                                                 LOC  \\\n",
       "0  {'Earth': 2, 'Central Europe': 1, 'south': 1, ...   \n",
       "1  {'North Atlantic': 2, 'Central Europe': 1, 'th...   \n",
       "2                  {'Central Europe': 1, 'earth': 1}   \n",
       "3                              {'Central Europe': 1}   \n",
       "4  {'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...   \n",
       "5                              {'Central Europe': 1}   \n",
       "6                              {'Central Europe': 1}   \n",
       "7                              {'Central Europe': 1}   \n",
       "8                              {'Central Europe': 1}   \n",
       "9                 {'Europe': 2, 'Central Europe': 1}   \n",
       "\n",
       "                                             CLIMATE  \n",
       "0  {'sea-level rise': 3, 'ocean': 2, 'flooding': ...  \n",
       "1  {'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...  \n",
       "2  {'climate change': 3, 'IPCC': 2, 'Climate chan...  \n",
       "3  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "4  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "5  {'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...  \n",
       "6  {'rise': 1, 'oligarchs': 1, 'climate changes':...  \n",
       "7  {'Net Zero': 2, 'rise': 1, 'good position': 1,...  \n",
       "8  {'greenhouse gases': 3, 'CO2 emissions': 2, 'o...  \n",
       "9  {'net-zero emissions': 3, 'emissions': 2, 'ris...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_sample_df['body'] = articles_sample_df['body'].apply(basic_preprocess_keepstopwords)\n",
    "\n",
    "articles_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275e86e",
   "metadata": {},
   "source": [
    "## Step 3: Sentence Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f77aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LOC</th>\n",
       "      <th>CLIMATE</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>san francisco this video can not be played gr...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 9, 'Ukraine': 2, 'San Francisco'...</td>\n",
       "      <td>{'Earth': 2, 'Central Europe': 1, 'south': 1, ...</td>\n",
       "      <td>{'sea-level rise': 3, 'ocean': 2, 'flooding': ...</td>\n",
       "      <td>[ san francisco this video can not be played g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north atlantic hurricanes are retaining far mo...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{'Hurricane Theta': 1}</td>\n",
       "      <td>{'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'North Atlantic': 2, 'Central Europe': 1, 'th...</td>\n",
       "      <td>{'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...</td>\n",
       "      <td>[north atlantic hurricanes are retaining far m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us president donald trump has accused climate ...</td>\n",
       "      <td>{'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...</td>\n",
       "      <td>{'Central Europe': 1, 'earth': 1}</td>\n",
       "      <td>{'climate change': 3, 'IPCC': 2, 'Climate chan...</td>\n",
       "      <td>[us president donald trump has accused climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video can not be played sir ed davey has won t...</td>\n",
       "      <td>{'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...</td>\n",
       "      <td>{'BBC': 2, 'Parliament': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "      <td>[video can not be played sir ed davey has won ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greenland is not used to being the centre of a...</td>\n",
       "      <td>{'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...</td>\n",
       "      <td>{'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greenland': 22, 'US': 14, 'China': 4, 'Denma...</td>\n",
       "      <td>{'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "      <td>[greenland is not used to being the centre of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft is poised to launch its game streami...</td>\n",
       "      <td>{'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...</td>\n",
       "      <td>{'Microsoft': 3, 'Google': 2, 'Lancaster Unive...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...</td>\n",
       "      <td>[microsoft is poised to launch its game stream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video can not be played a frequent flyer tax p...</td>\n",
       "      <td>{'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...</td>\n",
       "      <td>{'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'rise': 1, 'oligarchs': 1, 'climate changes':...</td>\n",
       "      <td>[video can not be played a frequent flyer tax ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>people must use less transport eat less red me...</td>\n",
       "      <td>{'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...</td>\n",
       "      <td>{'BBC': 1, 'the Confederation of British Indus...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'Net Zero': 2, 'rise': 1, 'good position': 1,...</td>\n",
       "      <td>[people must use less transport eat less red m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>verely hindered progress in co2 emissions redu...</td>\n",
       "      <td>{'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...</td>\n",
       "      <td>{'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...</td>\n",
       "      <td>{'Central Europe': 1}</td>\n",
       "      <td>{'greenhouse gases': 3, 'CO2 emissions': 2, 'o...</td>\n",
       "      <td>[verely hindered progress in co2 emissions red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>european union says it is aiming to become the...</td>\n",
       "      <td>{'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...</td>\n",
       "      <td>{'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...</td>\n",
       "      <td>{'Europe': 2, 'Central Europe': 1}</td>\n",
       "      <td>{'net-zero emissions': 3, 'emissions': 2, 'ris...</td>\n",
       "      <td>[european union says it is aiming to become th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0   san francisco this video can not be played gr...   \n",
       "1  north atlantic hurricanes are retaining far mo...   \n",
       "2  us president donald trump has accused climate ...   \n",
       "3  video can not be played sir ed davey has won t...   \n",
       "4  greenland is not used to being the centre of a...   \n",
       "5  microsoft is poised to launch its game streami...   \n",
       "6  video can not be played a frequent flyer tax p...   \n",
       "7  people must use less transport eat less red me...   \n",
       "8  verely hindered progress in co2 emissions redu...   \n",
       "9  european union says it is aiming to become the...   \n",
       "\n",
       "                                              PERSON  \\\n",
       "0  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "1  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "2  {'Trump': 7, 'Alan Shearer': 1, 'Gary Lineker'...   \n",
       "3  {'Ed': 9, 'Ms Moran': 4, 'Jo Swinson': 2, 'Ms ...   \n",
       "4  {'Greenlandic': 2, 'Greenland': 2, 'Alan Shear...   \n",
       "5  {'Hazas': 3, 'Lancaster': 2, 'Alan Shearer': 1...   \n",
       "6  {'Covid': 3, 'Extinction Rebellion': 2, 'Alan ...   \n",
       "7  {'Ian': 7, 'Brexit': 2, 'Alan Shearer': 1, 'Ga...   \n",
       "8  {'Alan Shearer': 1, 'Gary Lineker': 1, 'Robert...   \n",
       "9  {'Cañete': 2, 'Alan Shearer': 1, 'Gary Lineker...   \n",
       "\n",
       "                                                 ORG                   EVENT  \\\n",
       "0  {'BBC News': 2, 'BBC': 1, 'Copernicus': 1, 'th...                      {}   \n",
       "1  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...  {'Hurricane Theta': 1}   \n",
       "2  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "3  {'BBC': 2, 'Parliament': 2, 'Micah Richards': ...                      {}   \n",
       "4  {'BBC': 2, 'Copenhagen': 2, 'Micah Richards': ...                      {}   \n",
       "5  {'Microsoft': 3, 'Google': 2, 'Lancaster Unive...                      {}   \n",
       "6  {'BBC': 1, 'Micah Richards': 1, 'Premier Leagu...                      {}   \n",
       "7  {'BBC': 1, 'the Confederation of British Indus...                      {}   \n",
       "8  {'BBC': 2, 'UN': 2, 'Micah Richards': 1, 'Prem...                      {}   \n",
       "9  {'EU': 11, 'UN': 2, '1.5C': 2, 'BBC': 1, 'Mica...                      {}   \n",
       "\n",
       "                                                 GPE  \\\n",
       "0  {'Greenland': 9, 'Ukraine': 2, 'San Francisco'...   \n",
       "1  {'Ukraine': 2, 'US': 2, 'Athens': 1, 'Norway':...   \n",
       "2  {'US': 6, 'Ukraine': 2, 'Paris': 2, 'Athens': ...   \n",
       "3  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "4  {'Greenland': 22, 'US': 14, 'China': 4, 'Denma...   \n",
       "5  {'Ukraine': 2, 'Athens': 1, 'Norway': 1, 'US':...   \n",
       "6  {'UK': 3, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "7  {'UK': 6, 'Ukraine': 2, 'Athens': 1, 'Norway':...   \n",
       "8  {'Ukraine': 2, 'Paris': 2, 'Athens': 1, 'Norwa...   \n",
       "9  {'Ukraine': 2, 'Sweden': 2, 'Poland': 2, 'Pari...   \n",
       "\n",
       "                                                 LOC  \\\n",
       "0  {'Earth': 2, 'Central Europe': 1, 'south': 1, ...   \n",
       "1  {'North Atlantic': 2, 'Central Europe': 1, 'th...   \n",
       "2                  {'Central Europe': 1, 'earth': 1}   \n",
       "3                              {'Central Europe': 1}   \n",
       "4  {'Arctic': 2, 'Central Europe': 1, 'Arctic Oce...   \n",
       "5                              {'Central Europe': 1}   \n",
       "6                              {'Central Europe': 1}   \n",
       "7                              {'Central Europe': 1}   \n",
       "8                              {'Central Europe': 1}   \n",
       "9                 {'Europe': 2, 'Central Europe': 1}   \n",
       "\n",
       "                                             CLIMATE  \\\n",
       "0  {'sea-level rise': 3, 'ocean': 2, 'flooding': ...   \n",
       "1  {'storms': 3, 'hurricanes': 2, 'rise': 1, 'oli...   \n",
       "2  {'climate change': 3, 'IPCC': 2, 'Climate chan...   \n",
       "3  {'rise': 1, 'oligarchs': 1, 'climate changes':...   \n",
       "4  {'rise': 1, 'oligarchs': 1, 'climate changes':...   \n",
       "5  {'cloud': 3, 'carbon neutral': 2, 'rise': 1, '...   \n",
       "6  {'rise': 1, 'oligarchs': 1, 'climate changes':...   \n",
       "7  {'Net Zero': 2, 'rise': 1, 'good position': 1,...   \n",
       "8  {'greenhouse gases': 3, 'CO2 emissions': 2, 'o...   \n",
       "9  {'net-zero emissions': 3, 'emissions': 2, 'ris...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [ san francisco this video can not be played g...  \n",
       "1  [north atlantic hurricanes are retaining far m...  \n",
       "2  [us president donald trump has accused climate...  \n",
       "3  [video can not be played sir ed davey has won ...  \n",
       "4  [greenland is not used to being the centre of ...  \n",
       "5  [microsoft is poised to launch its game stream...  \n",
       "6  [video can not be played a frequent flyer tax ...  \n",
       "7  [people must use less transport eat less red m...  \n",
       "8  [verely hindered progress in co2 emissions red...  \n",
       "9  [european union says it is aiming to become th...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_sample_df['sentences'] = articles_sample_df['body'].apply(sent_tokenize)\n",
    "\n",
    "articles_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5dfa50",
   "metadata": {},
   "source": [
    "## Step 4: Filter out factual sentences with the entity & retrieve its contextual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a193f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_opinion_classification(df):\n",
    "    nerdict = ['PERSON', 'ORG', 'EVENT', 'GPE', 'LOC', 'CLIMATE']\n",
    "    ner_dict = {}\n",
    "    \n",
    "    # each entity type\n",
    "    for ner in nerdict:\n",
    "        ner_term_dict = {}\n",
    "        # each key in entity type\n",
    "        for ner_term in df[ner]:\n",
    "            ner_term = ner_term.replace(\"'\", \"\")\n",
    "            # each sentence in the article \n",
    "            for idx, sentence in enumerate(df['sentences']):\n",
    "                if ner_term.lower() in sentence:\n",
    "                    sentence_result = fact_opinion_classifier(sentence)[0]\n",
    "                    #print(sentence, sentence_result)\n",
    "                    # if it is an opinionated sentence\n",
    "                    if  sentence_result[\"label\"] == \"LABEL_0\":\n",
    "                        passage = \"\"\n",
    "                        # get all the window sentences\n",
    "                        if (idx != 0 and (idx != len(df['sentences']) - 1)):\n",
    "                            passage = df['sentences'][idx-1] + sentence + df['sentences'][idx+1]\n",
    "                        # if it is the first sentence\n",
    "                        elif (idx == 0):\n",
    "                            passage = sentence + df['sentences'][idx+1]\n",
    "                        # if it is the last sentence\n",
    "                        else:\n",
    "                            passage = df['sentences'][idx-1] + sentence \n",
    "                        # add the sub-document\n",
    "                        if ner_term in ner_term_dict:\n",
    "                            ner_term_dict[ner_term] = ner_term_dict[ner_term] + \" \" + passage\n",
    "                        else:\n",
    "                            ner_term_dict[ner_term] = passage\n",
    "                            \n",
    "        ner_dict[ner] = ner_term_dict             \n",
    "           \n",
    "    df['ner_sentences'] = ner_dict\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sample_df = articles_sample_df.apply(fact_opinion_classification, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffae485",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b771db",
   "metadata": {},
   "source": [
    "## Step 5: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_vader(df):\n",
    "    nerdict = ['PERSON', 'ORG', 'EVENT', 'GPE', 'LOC', 'CLIMATE']\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    for ner in nerdict:\n",
    "        sentiment_result_dict = {}\n",
    "        for ner_term in df[ner]:\n",
    "            result = sid.polarity_scores(df[ner][ner_term])\n",
    "            if result['compound'] > 0.05:\n",
    "                sentiment_result_dict[ner_term] =  ('Positive', result['compound'])\n",
    "            elif result['compound'] < -0.05:\n",
    "                sentiment_result_dict[ner_term] = ('Negative', result['compound'])\n",
    "            else:\n",
    "                sentiment_result_dict[ner_term] = (\"Neutral\", result['compound'])\n",
    "\n",
    "        df[ner] = sentiment_result_dict\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sample_df['sentiment'] = articles_sample_df['ner_sentences'].apply(sentiment_analysis_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffdf1a",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57739e",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d2dca",
   "metadata": {},
   "source": [
    "# Aggrgated Insights\n",
    "\n",
    "For this segment, we only used BBC & CNN dataset due to time limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629f75d",
   "metadata": {},
   "source": [
    "### 1. Upload articles with their sentiment scoring for each entity term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e451f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sentiment_df = pd.read_csv('article_entity_sentiment.csv')\n",
    "\n",
    "entity_sentiment_df = entity_sentiment_df[['sentiment']]\n",
    "\n",
    "entity_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955745c4",
   "metadata": {},
   "source": [
    "### 2. Upload top 20 NER terms for each entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d76a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_file = open(\"ner.txt\", \"r\")\n",
    "\n",
    "ner_list = json.loads(ner_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ner in ner_list:\n",
    "    term_dict = {}\n",
    "    for term in ner_list[ner]:\n",
    "        term_dict[term] = [0,0]\n",
    "    ner_list[ner] = term_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88486372",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2375f2a",
   "metadata": {},
   "source": [
    "### 3. Get the sentiment score for each entity term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_type = ['PERSON', 'ORG', 'EVENT', 'GPE', 'LOC', 'CLIMATE']\n",
    "\n",
    "def get_sentiment_score_by_entity_term(df):\n",
    "    res = ast.literal_eval(df['sentiment'])\n",
    "    for ner in ner_type:\n",
    "        for term in ner_list[ner]:\n",
    "            if term in res[ner]:\n",
    "                ner_list[ner][term][0] += res[ner][term][1]\n",
    "                ner_list[ner][term][1] += 1\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47287fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = entity_sentiment_df.apply(get_sentiment_score_by_entity_term, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85898b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ner in ner_type:\n",
    "    for term in ner_list[ner]:\n",
    "        if ner_list[ner][term][1] != 0:\n",
    "            ner_list[ner][term] = ner_list[ner][term][0] / ner_list[ner][term][1]\n",
    "        else:\n",
    "            ner_list[ner][term] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d079649",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ner_sentiment_score.txt\", \"w\")\n",
    "f.write(str(ner_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f46b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276cc06",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd61f36",
   "metadata": {},
   "source": [
    "# Training & Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55df5f6",
   "metadata": {},
   "source": [
    "### 1. Upload Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Sentiment_Labelling.xlsx')\n",
    "\n",
    "data = data[['Sentences', 'Label']]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda52b6",
   "metadata": {},
   "source": [
    "### 2. Pre-processing & Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess_keepstopwords(self_text):\n",
    "    # 1. Remove html tags\n",
    "    words = BeautifulSoup(self_text, features=\"html.parser\").get_text()\n",
    "    \n",
    "    # 2. Convert words to lower case and split each word up\n",
    "    words = self_text.lower()\n",
    "    words = words.replace('\\n','')\n",
    "    \n",
    "    # remove punctuation \n",
    "    punc = '''()-[]{};:\\,<>/@#$%^&*_~'''\n",
    "    for ele in punc:\n",
    "        words = words.replace(ele, \"\")\n",
    "     \n",
    "    words = words.encode('ascii', 'ignore')\n",
    "    words = words.decode()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentences'] = data['Sentences'].apply(basic_preprocess_keepstopwords)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['Sentences'].values\n",
    "labels = data['Label'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19aa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% train and 20% test \n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, random_state=88, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af898c9",
   "metadata": {},
   "source": [
    "### 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec4d2e",
   "metadata": {},
   "source": [
    "#### Naive Bays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0361581",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "\n",
    "for text in train_sentences:\n",
    "    sent = nltk.word_tokenize(text)\n",
    "    train_corpus.append(sent)\n",
    "    \n",
    "train_dictionary = gensim.corpora.Dictionary(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_training_data = []\n",
    "\n",
    "for (l, s) in zip(train_labels, train_corpus):\n",
    "    # Convert the original sentence into a vector.\n",
    "    vector = train_dictionary.doc2bow(s)\n",
    "    \n",
    "    # Create a dict object to store the document vector (in order to use NLTK's classifier later)\n",
    "    sent_as_dict = {id:1 for (id, tf) in vector}\n",
    "    \n",
    "    # Add the labeled sentence to the labeled data set.\n",
    "    labeled_training_data.append((sent_as_dict, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = []\n",
    "\n",
    "for text in test_sentences:\n",
    "    sent = nltk.word_tokenize(text)\n",
    "    test_corpus.append(sent)\n",
    "    \n",
    "test_dictionary = gensim.corpora.Dictionary(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_test_data = []\n",
    "\n",
    "for (l, s) in zip(test_labels, test_corpus):\n",
    "\n",
    "    # Convert the original sentence into a vector.\n",
    "    vector = test_dictionary.doc2bow(s)\n",
    "    \n",
    "    # Create a dict object to store the document vector (in order to use NLTK's classifier later)\n",
    "    sent_as_dict = {id:1 for (id, tf) in vector}\n",
    "    \n",
    "    # Add the labeled sentence to the labeled data set.\n",
    "    labeled_test_data.append((sent_as_dict, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd130ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(labeled_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accurary\n",
    "print(\"Accuracy on Naive Bays: \", nltk.classify.accuracy(classifier, labeled_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a3ba7",
   "metadata": {},
   "source": [
    "#### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49656f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_textblob(sentence):\n",
    "    def getSubjectivity(text):\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "  \n",
    "    #Create a function to get the polarity\n",
    "    def getPolarity(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    news = {'Sentences' : sentence}\n",
    "\n",
    "    #Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "    news['TextBlob_Subjectivity'] = getSubjectivity(news['Sentences'])\n",
    "    news['TextBlob_Polarity'] = getPolarity(news['Sentences'])\n",
    "    \n",
    "    def getAnalysis(score):\n",
    "        if score < 0:\n",
    "            return 0\n",
    "        elif score == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    news['TextBlob_Analysis'] = getAnalysis(news['TextBlob_Polarity'])\n",
    "    return news['TextBlob_Analysis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data={'sentence': test_sentences, 'labels': test_labels})\n",
    "\n",
    "test_df['textblob_scores'] = test_df['sentence'].apply(sentiment_analysis_textblob)\n",
    "\n",
    "print(\"Accuracy on TextBlob: \", accuracy_score(test_df['labels'],test_df['textblob_scores']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a510b",
   "metadata": {},
   "source": [
    "#### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_vader(sentence):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    result = sid.polarity_scores(sentence)\n",
    "        \n",
    "    if result['compound'] > 0.05:\n",
    "        sentiment_result =  2\n",
    "    elif result['compound'] < -0.05:\n",
    "        sentiment_result = 0\n",
    "    else:\n",
    "        sentiment_result = 1\n",
    "    \n",
    "    return sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data={'sentence': test_sentences, 'labels': test_labels})\n",
    "\n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "test_df['vader_scores'] = test_df['sentence'].apply(sentiment_analysis_vader)\n",
    "\n",
    "print(\"Accuracy on VADER: \", accuracy_score(test_df['labels'],test_df['vader_scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77721d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
